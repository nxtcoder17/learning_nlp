{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load ('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8963e-01, -4.0309e-01,  3.5350e-01, -4.7907e-01, -4.3311e-01,\n",
       "        2.3857e-01,  2.6962e-01,  6.4332e-02,  3.0767e-01,  1.3712e+00,\n",
       "       -3.7582e-01, -2.2713e-01, -3.5657e-01, -2.5355e-01,  1.7543e-02,\n",
       "        3.3962e-01,  7.4723e-02,  5.1226e-01, -3.9759e-01,  5.1333e-03,\n",
       "       -3.0929e-01,  4.8911e-02, -1.8610e-01, -4.1702e-01, -8.1639e-01,\n",
       "       -1.6908e-01, -2.6246e-01, -1.5983e-02,  1.2479e-01, -3.7276e-02,\n",
       "       -5.7125e-01, -1.6296e-01,  1.2376e-01, -5.5464e-02,  1.3244e-01,\n",
       "        2.7519e-02,  1.2592e-01, -3.2722e-01, -4.9165e-01, -3.5559e-01,\n",
       "       -3.0630e-01,  6.1185e-02, -1.6932e-01, -6.2405e-02,  6.5763e-01,\n",
       "       -2.7925e-01, -3.0450e-03, -2.2400e-02, -2.8015e-01, -2.1975e-01,\n",
       "       -4.3188e-01,  3.9864e-02, -2.2102e-01, -4.2693e-02,  5.2748e-02,\n",
       "        2.8726e-01,  1.2315e-01, -2.8662e-02,  7.8294e-02,  4.6754e-01,\n",
       "       -2.4589e-01, -1.1064e-01,  7.2250e-02, -9.4980e-02, -2.7548e-01,\n",
       "       -5.4097e-01,  1.2823e-01, -8.2408e-02,  3.1035e-01, -6.3394e-02,\n",
       "       -7.3755e-01, -5.4992e-01,  9.9999e-02, -2.0758e-01, -3.9674e-02,\n",
       "        2.0664e-01, -9.7557e-02, -3.7092e-01,  2.7901e-01, -6.2218e-01,\n",
       "       -1.0280e-01,  2.3271e-01,  4.3838e-01,  3.2445e-02, -2.9866e-01,\n",
       "       -7.3611e-02,  7.1594e-01,  1.4241e-01,  2.7770e-01, -3.9892e-01,\n",
       "        3.6656e-02,  1.5759e-01,  8.2014e-02, -5.7343e-01,  3.5457e-01,\n",
       "        2.2491e-01, -6.2699e-01, -8.8106e-02,  2.4361e-01,  3.8533e-01,\n",
       "       -1.4083e-01,  1.7691e-01,  7.0897e-02,  1.7951e-01, -4.5907e-01,\n",
       "       -8.2120e-01, -2.6631e-02,  6.2549e-02,  4.2415e-01, -8.9630e-02,\n",
       "       -2.4654e-01,  1.4156e-01,  4.0187e-01, -4.1232e-01,  8.4516e-02,\n",
       "       -1.0626e-01,  7.3145e-01,  1.9217e-01,  1.4240e-01,  2.8511e-01,\n",
       "       -2.9454e-01, -2.1948e-01,  9.0460e-01, -1.9098e-01, -1.0340e+00,\n",
       "       -1.5754e-01, -1.1964e-01,  4.9888e-01, -1.0624e+00, -3.2820e-01,\n",
       "       -1.1232e-02, -7.9482e-01,  3.7275e-01, -6.8710e-03, -2.5772e-01,\n",
       "       -4.7005e-01, -4.1387e-01, -6.4089e-02, -2.8033e-01, -4.0778e-02,\n",
       "       -2.4866e+00,  6.2494e-03, -1.0210e-02,  1.2752e-01,  3.4965e-01,\n",
       "       -1.2571e-01,  3.1570e-01,  4.1926e-01,  2.0056e-01, -5.5984e-01,\n",
       "       -2.2801e-01,  1.2012e-01, -2.0518e-03, -8.9764e-02, -8.0373e-02,\n",
       "        1.1969e-02, -2.6978e-01,  3.4829e-01,  7.3664e-03, -1.1137e-01,\n",
       "        6.3410e-01,  3.8449e-01, -6.2248e-01,  4.1145e-02,  2.5922e-01,\n",
       "        6.5811e-01, -4.9548e-01, -1.3030e-01, -3.8279e-01,  1.1156e-01,\n",
       "       -4.3085e-01,  3.4473e-01,  2.7109e-02, -2.5108e-01, -2.8011e-01,\n",
       "        2.1662e-01,  3.2660e-01,  5.5895e-02,  7.6077e-02, -5.2480e-02,\n",
       "        4.5928e-02, -2.5266e-01,  5.2845e-01, -1.3145e-01, -1.2453e-01,\n",
       "        4.0556e-01,  3.1877e-01,  2.4415e-02, -2.2620e-01, -6.1960e-01,\n",
       "       -4.0886e-01, -3.5534e-02, -5.5123e-03,  2.3438e-01,  8.7854e-01,\n",
       "       -2.5161e-01,  4.0600e-01, -4.4284e-01,  3.4934e-01, -5.6429e-01,\n",
       "       -2.3676e-01,  6.2199e-01, -2.8175e-01,  4.2024e-01,  1.0043e-01,\n",
       "       -1.4720e-01,  4.9593e-01, -3.5850e-01, -1.3998e-01, -2.7494e-01,\n",
       "        2.3827e-01,  5.7268e-01,  7.9025e-02,  1.7872e-02, -2.1829e-01,\n",
       "        5.5050e-02, -5.4200e-01,  1.6788e-01,  3.9065e-01,  3.0209e-01,\n",
       "        2.3040e-01, -3.9351e-02, -2.1078e-01, -2.7224e-01,  1.6907e-01,\n",
       "        5.4819e-01,  9.4888e-02,  7.9798e-01, -6.6158e-02,  1.9844e-01,\n",
       "        2.0307e-01,  4.4808e-02, -1.0240e-01, -6.9909e-02, -3.6756e-02,\n",
       "        9.5159e-02, -2.7830e-01, -1.0597e-01, -1.6276e-01, -1.8211e-01,\n",
       "       -3.1897e-01, -2.1633e-01,  1.4994e-01, -7.2057e-02,  2.2264e-01,\n",
       "       -4.5551e-01,  3.0341e-01,  1.8431e-01,  2.1681e-01, -3.1940e-01,\n",
       "        2.6426e-01,  5.8106e-01,  5.4635e-02,  6.3238e-01,  4.3169e-01,\n",
       "        9.0343e-02,  1.9494e-01,  3.5483e-01, -2.0706e-02, -7.3117e-01,\n",
       "        1.2941e-01,  1.7418e-01, -1.5065e-01,  5.3355e-02,  4.4794e-02,\n",
       "       -1.6600e-01,  2.2007e-01, -5.3970e-01, -2.4968e-01, -2.6464e-01,\n",
       "       -5.5515e-01,  5.8242e-01,  2.2295e-01,  2.4433e-01,  4.5275e-01,\n",
       "        3.4693e-01,  1.2255e-01, -3.9059e-02, -3.2749e-01, -2.7891e-01,\n",
       "        1.3766e-01,  3.8392e-01,  1.0543e-03, -1.0242e-02,  4.9205e-01,\n",
       "       -1.7922e-01,  4.1215e-02,  1.3547e-01, -2.0598e-01, -2.3194e-01,\n",
       "       -7.7701e-01, -3.8237e-01, -7.6383e-01,  1.9418e-01, -1.5441e-01,\n",
       "        8.9740e-01,  3.0626e-01,  4.0376e-01,  2.1738e-01, -3.8050e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp ('lion').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for a vector of a Document (_a collection of tokens_) are essentially the **Average** of corresponding values of all of it's tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.72348157e-01,  1.13993334e-02, -5.07186651e-02,  3.04736700e-02,\n",
       "        1.02041634e-02,  1.36314198e-01, -1.43308327e-01, -1.56106679e-02,\n",
       "        8.28423277e-02,  1.67149007e+00, -3.76483351e-01,  8.27163458e-04,\n",
       "        3.39448266e-02, -1.83933794e-01, -2.17978001e-01,  2.91569922e-02,\n",
       "        7.38043338e-02,  1.03464663e+00, -6.53124973e-02, -3.02769482e-01,\n",
       "       -1.21348329e-01, -2.10911278e-02, -5.04233642e-03, -1.49620354e-01,\n",
       "        7.19222352e-02, -1.14348307e-02, -2.94718355e-01, -9.38479975e-02,\n",
       "        2.39413325e-02, -2.36319661e-01, -1.38145790e-01,  1.62768334e-01,\n",
       "        8.31211656e-02, -1.94691680e-02,  3.39896716e-02, -9.83766690e-02,\n",
       "        1.40833361e-02,  4.41392362e-02, -3.44334841e-02, -1.59693331e-01,\n",
       "        1.34939671e-01, -5.46016656e-02,  4.42504995e-02, -1.69036329e-01,\n",
       "        1.77600995e-01,  1.24370992e-01, -2.35389009e-01, -1.37921795e-02,\n",
       "        1.09435163e-01, -3.67643349e-02, -1.80684015e-01,  5.96696734e-02,\n",
       "        1.74656641e-02, -7.17661679e-02, -6.61126673e-02, -1.09719314e-01,\n",
       "        1.41698373e-02,  1.91254839e-01, -9.73803103e-02, -1.51510000e-01,\n",
       "       -2.09343191e-02,  6.82264939e-02,  1.18707992e-01,  9.74266753e-02,\n",
       "       -3.40083279e-02, -1.03336006e-01,  5.08633256e-02, -6.30299971e-02,\n",
       "        5.92953302e-02,  5.53583317e-02,  6.48783371e-02, -2.28066742e-03,\n",
       "        1.26583174e-01,  8.70158374e-02, -4.44749929e-03, -2.06522688e-01,\n",
       "       -4.71662320e-02, -8.40654969e-02, -2.45656613e-02,  9.79383755e-03,\n",
       "       -1.17304839e-01,  1.58294320e-01,  3.11616552e-03,  8.15537497e-02,\n",
       "        1.04149997e-01, -6.53666630e-02,  6.39293313e-01,  3.07845324e-01,\n",
       "        2.16024518e-01,  1.93165496e-01, -5.76967001e-03,  1.37018174e-01,\n",
       "        4.62698340e-02, -2.81591833e-01,  1.44620016e-01, -1.11784495e-01,\n",
       "       -1.18120670e-01, -4.80088331e-02, -1.66833401e-02, -1.96337163e-01,\n",
       "        1.20270170e-01,  1.80233326e-02, -1.45326167e-01, -5.51203303e-02,\n",
       "        2.73249988e-02, -5.16038358e-01,  1.91133320e-01, -1.22211665e-01,\n",
       "       -2.59749964e-03,  7.00750714e-03,  8.39066971e-03, -1.35709658e-01,\n",
       "        1.35878846e-01, -2.36315653e-01,  5.24155013e-02,  1.49114206e-01,\n",
       "        4.54239994e-02, -4.82251644e-02,  1.01726674e-01, -9.57133342e-03,\n",
       "        3.67553346e-02, -1.01855330e-01, -6.04298944e-03, -8.09980929e-02,\n",
       "       -3.36291641e-01,  1.84029162e-01,  2.47116685e-02, -1.12581670e-01,\n",
       "       -5.81233716e-03, -7.20183328e-02, -3.13029960e-02, -1.41354665e-01,\n",
       "       -1.64832518e-01,  8.83055031e-02,  9.45433304e-02, -1.53148221e-02,\n",
       "       -1.34640023e-01, -3.86001654e-02, -3.61458212e-03, -1.42154828e-01,\n",
       "       -1.88576663e+00,  3.35009955e-02,  1.57609835e-01,  4.99090068e-02,\n",
       "        1.89496160e-01, -2.12626662e-02, -2.15516668e-02,  7.24731609e-02,\n",
       "        8.66766274e-03,  9.42646787e-02, -2.91667879e-04, -1.01367168e-01,\n",
       "        1.53941169e-01, -6.66393265e-02, -2.07546353e-01,  4.31144983e-02,\n",
       "       -1.40432000e-01,  8.92028436e-02,  1.12764664e-01, -6.32440001e-02,\n",
       "        1.91204976e-02, -1.67245671e-01, -2.31281996e-01, -1.09815836e-01,\n",
       "       -5.72183318e-02, -1.72321364e-01, -8.06841627e-02, -7.53138289e-02,\n",
       "       -7.47766793e-02, -1.33558840e-01,  1.17644824e-01,  1.23049997e-01,\n",
       "       -2.42766678e-01, -1.69516161e-01, -3.07324558e-01, -1.22464828e-01,\n",
       "        2.35831156e-01, -4.39061671e-02, -6.08321689e-02, -3.16768326e-02,\n",
       "       -6.72871694e-02, -1.29388168e-01, -2.34830007e-01, -1.63076654e-01,\n",
       "        8.47813413e-02,  9.03469920e-02,  5.55500388e-03, -7.37408400e-02,\n",
       "        4.81573343e-02,  2.18493640e-02,  2.44528174e-01,  3.39303315e-02,\n",
       "        1.44109473e-01,  8.06901678e-02,  3.16652991e-02,  1.57057181e-01,\n",
       "        1.77248836e-01,  2.25648433e-02,  1.22988299e-02,  2.11349931e-02,\n",
       "       -1.01100005e-01,  2.20666658e-02, -2.37653330e-01, -6.93366677e-03,\n",
       "        2.02759996e-01,  8.33157972e-02, -1.36916712e-03, -1.18423671e-01,\n",
       "       -1.10906102e-01,  1.94599666e-03,  5.52299954e-02,  7.26608261e-02,\n",
       "       -4.57321666e-02,  2.00092331e-01,  1.18461840e-01,  1.01085491e-01,\n",
       "       -2.43595675e-01,  7.90551677e-02, -2.37403288e-02,  2.29074836e-01,\n",
       "        3.87624986e-02, -1.96351632e-02, -6.93934932e-02,  1.58265933e-01,\n",
       "       -1.71144798e-01, -1.88479498e-01,  1.12610161e-01,  1.30915985e-01,\n",
       "        2.46765018e-02,  3.28103364e-01,  2.63633323e-03, -7.40053281e-02,\n",
       "       -3.99050489e-02,  2.82426625e-02, -2.77313292e-02, -6.11263327e-02,\n",
       "       -1.27709657e-01, -2.75812354e-02,  1.51445508e-01,  1.90836310e-01,\n",
       "       -1.82828322e-01, -1.17210835e-01, -5.56183346e-02, -2.79840026e-02,\n",
       "        7.20854998e-02, -1.75568163e-01, -1.14969678e-01,  4.53806706e-02,\n",
       "       -1.92146167e-01,  9.48750004e-02,  1.45831704e-02, -6.51098266e-02,\n",
       "       -1.96280003e-01,  7.69335404e-02,  1.73190832e-01,  6.63891733e-02,\n",
       "        2.27989152e-01,  7.46954978e-02, -2.68350001e-02, -2.69631669e-02,\n",
       "        1.01348318e-01,  1.38241827e-01,  1.57494828e-01, -1.29496679e-01,\n",
       "        1.51328325e-01, -2.29259670e-01,  2.70494986e-02, -4.56630029e-02,\n",
       "       -6.39849976e-02,  1.11799993e-01, -4.48553264e-02,  2.37554148e-01,\n",
       "       -2.41809506e-02, -1.66229501e-01, -9.95300040e-02, -1.92856658e-02,\n",
       "        6.83349967e-02,  9.48563293e-02, -1.76676735e-02,  7.12607503e-02,\n",
       "        2.21339986e-01,  1.35483837e-03, -7.96278343e-02,  8.08006600e-02,\n",
       "       -6.23431690e-02, -2.69403383e-02,  4.52483296e-02,  2.10628416e-02,\n",
       "        2.38348339e-02,  2.99449917e-02, -1.95069000e-01,  1.40125483e-01,\n",
       "       -7.08448365e-02, -9.35746729e-02, -1.12756334e-01,  2.81260032e-02,\n",
       "        4.69838381e-02,  5.86768389e-02, -1.61301494e-01, -1.79183409e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp ('The quick brown fox jumped.').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp ('The quick brown fox jumped.').vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp (\"lion cat pet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion AND lion : 1.0\n",
      "lion AND cat : 0.5265437960624695\n",
      "lion AND pet : 0.39923766255378723\n",
      "cat AND lion : 0.5265437960624695\n",
      "cat AND cat : 1.0\n",
      "cat AND pet : 0.7505456805229187\n",
      "pet AND lion : 0.39923766255378723\n",
      "pet AND cat : 0.7505456805229187\n",
      "pet AND pet : 1.0\n"
     ]
    }
   ],
   "source": [
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        print (f\"{token1.text} AND {token2.text} : {token1.similarity (token2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should keep in mind that **Words that have quite opposite meaning but often appear in the same context** may actually have **SIMILAR Vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp (\"like love hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like AND like : 1.0\n",
      "like AND love : 0.6579040288925171\n",
      "like AND hate : 0.6574651598930359\n",
      "love AND like : 0.6579040288925171\n",
      "love AND love : 1.0\n",
      "love AND hate : 0.6393099427223206\n",
      "hate AND like : 0.6574651598930359\n",
      "hate AND love : 0.6393099427223206\n",
      "hate AND hate : 1.0\n"
     ]
    }
   ],
   "source": [
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        print (f\"{token1.text} AND {token2.text} : {token1.similarity (token2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "margle False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp (\"dog cat margle\")\n",
    "for token in tokens:\n",
    "    print (token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = lambda vec1, vec2: 1 - spatial.distance.cosine (vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating vectors for king, woman and man\n",
    "king, man, woman = [x.vector for x in nlp (\"king man woman\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector = king - man + woman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this **new_vector** should be somewhat similar to **queen** or **princess** etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating in the entire corpus of word vectors to find similar word vectors\n",
    "computed_similarities = []\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector and word.is_lower and word.is_alpha:\n",
    "        similarity = cosine_similarity (new_vector, word.vector)\n",
    "        computed_similarities.append ( (word, similarity) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key param in sorted () is the key on which sorting would take place, and - is there for Descending order\n",
    "computed_similarities = sorted (computed_similarities, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king', 'queen', 'prince', 'kings', 'princess', 'royal', 'throne', 'queens', 'monarch', 'kingdom']\n"
     ]
    }
   ],
   "source": [
    "print ([t[0].text for t in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
